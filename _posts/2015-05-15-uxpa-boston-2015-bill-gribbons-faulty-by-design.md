---
layout: post
title:  "UXPA Boston 2015: Faulty by design (Bill Gribbons)"
date:   2015-05-15 12:00:00 -0400
---
_At the UXPA Boston 2015 conference, Bill Gribbons presented “Faulty by design: An examination of user decision making.”_

28 years of experience in product development, watching people interact with systems and **make bad decisions**

Often characterized as “human/user error” -> frustrated him as student of psychology humans are very bad at making decisions - you should expect it, particularly in stressful situations

Useful to walk through:

*   how humans make decisions
*   understand why they have problems
*   understand how to design to help them

This is not just “our users” this is every human… same fundamental problems apply to our organizations, our lives

What is decision making - primarily concerned with responding to uncertainty Factors include:

*   Expertise: some people are good at this, have developed heuristics about how to decide, very effective strategies (but when experts do make mistakes, it’s usually major/catastrophic)
*   Time-to-act: shorter time increase stress
*   What is the value of the outcome? what is the importance of decision
*   Cultural psychology changes everything: risk-averse or not?
*   How confident is user? Americans in particular are overly, falsely confident in ability to make decisions; can set up a dangerous situation for UX professionals
*   How much information is available? Often we overwhelm users with every piece of information, in excruciating detail, and users left to figure out what pieces are critical
*   As people age, working memory capacity decreases (this is where decision-making happens)
*   People with low literacy skills have even harder time - how do we support individuals we know are dealing with limitations
*   Fatigue - as day goes on (and for doctors can be very long shifts) abilities, tolerances decreasee

We assume that users are going to commit just the right amount of resources to make a decision, but usually they fall short. Tradeoffs begin in the mind - if I give up a bit up front, I’m ok with giving up a little on the result Sometimes we think decision-support is a sub-discipline of design: but it’s a fundamental part of design… thousands of little decisions in every application, particularly when complex Most decisions have little consequence, but some are big

Life requires more from us humans than we have attention to give

We never give enough attention… “When I see something go wrong, and a client says, ‘That person is lazy, inattentive.’ I have to say, ‘They’re not being lazy, they’re giving the bare minimum amount of attention to perform a task.’ In fact, they’re just being human.”

DESIGN WITH ASSUMPTION IN MIND - we will design/support very differently

Authors ARIELY, THALER/SUNSTEIN: look at finances and health… nothing is more important than those categories, right?

Example: #1 concern for Americans: having enough money to retire

*   BUT only just over half are actually saving

What people say DOES NOT EQUAL How people behave

Don’t design for “what people should do,” design for “how do we take a person from what they’re doing to what they want to do.”

Remember: we make these bad decisions ourselves, so we shouldn’t be surprised when our users do it

THREE MAIN PROBLEM AREAS: load, anxiety, and near-term focus

BIAS = very predictable systematic errors HEURISTICS = probability-based rules driven by patterns (not intuition)

KAHNEMAN “Thinking fast and slow” - when presented with a hard question, we try to find an easier question to answer… not always in conscious control of this

(LIFE HINT: Maintenance plans are never good - another way for companies to make money off of you.)

“Satisficing” = more often, people’s selections come up short, but they’re OK with it – most of life only requires “good enough” “near-term outlook” = need to retire in 20 years, but want sports car today

We are design to keep anxiety in check:

*   tunnel vision / cognitive narrowing (only choose from arbitrailiy limited set)
*   confirmational bias (want to be surrounded by data that confirms decision)
*   selective omission (ignore the things that challenge decision)
*   avoidance behavior (better to avoid problem than to deal with anxiety)

What does this mean for our users:

*   don’t design for hypothetical, rational user
*   we buy things because of bells and whistles, then we spend next 3 years complaining about complexity

compensate for the predictably irrational: “what if we designed a device without X, but you could get it cheaper and it was easier to use.” \[then prototypes quickly\] get to the point of what they’re actually going to do (and will be satisfied with)

HEALTH PLANS: 7 plans, 20 different coverage aspects, no comparison engine, no filters So, optimism bias: let’s just go cheap, because I’m sure I’ll be healthier next year “But, Bill, we’re giving them all the information, what’s wrong with them?” “So I buy the Cadillac plan at the last hour, because otherwise I’d be negligent as a father!”

HOW CAN WE SHIFT BURDEN OFF OF USER AND ONTO INTERFACE? e.g. comparison tool with filters, let user choose most important factors to compare

EBAY: Sellers had to make decision about pricing - user research showed high anxiety, “don’t want to leave money on the table, but don’t want it to be for sale for too long, gotta get this just right” - so people would abandon process. SO, showed them a bunch of similar products and how they were priced. Gave people just enough info, at the right time, to make a confident decision.

NUDGE: Premise is that people make bad decisions, so we can nudge people into making good decisions. “Beware the nudger” – on the one hand, we should support users with the RIGHT INFO, but DON’T NUDGE… leave the ultimate decision to the user. “For every good nudge, there are going to be 100 bad nudges.” As designers, we should be aware of subconscious attempts to influence decisions.
